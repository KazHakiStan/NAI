ChatGPT initially used a Microsoft Azure supercomputing infrastructure, powered by Nvidia GPUs, that Microsoft built specifically for OpenAI and that reportedly cost "hundreds of millions of dollars". Following ChatGPT's success, Microsoft dramatically upgraded the OpenAI infrastructure in 2023.[16] Scientists at the University of California, Riverside, estimate that a series of prompts to ChatGPT needs approximately 500 milliliters of water for Microsoft servers cooling.[17] TrendForce market intelligence estimated that 30,000 Nvidia GPUs (each costing approximately $10,000â€“$15,000) were used to power ChatGPT in 2023.[18][19]

OpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.