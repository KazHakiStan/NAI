OpenAI acknowledges that ChatGPT "sometimes writes plausible-sounding but incorrect or nonsensical answers".[10] This behavior is common for large language models, and is called "hallucination".[36] The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, in an example of an optimization pathology known as Goodhart's law.[37]

As of 2023, GPT-3.5, available in the free version of ChatGPT, has knowledge of events that occurred up to January 2022, and GPT-4, available with ChatGPT Plus, up to April 2023.

Training data also suffers from algorithmic bias, which may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap in which women and scientists of color were asserted to be inferior to white male scientists.[39][40] This negative misrepresentation of groups of individuals is an example of possible representational harm.